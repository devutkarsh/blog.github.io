[{"categories":null,"contents":"","date":"Sep 16","description":"AWS S3 for static content hosting in EKS","permalink":"https://blog.devutkarsh.com/projects/s3-streamer_project/","tags":null,"title":"S3 Streamer"},{"categories":null,"contents":"","date":"Jan 23","description":"Edge Proxy Gateway Microservice using Netflix Zuul on Java","permalink":"https://blog.devutkarsh.com/projects/gateway-service_project/","tags":null,"title":"Gateway Service"},{"categories":null,"contents":"","date":"May 26","description":"A very old URL shortner written on Java \u0026 Angular 2","permalink":"https://blog.devutkarsh.com/projects/url-shortner_projects/","tags":null,"title":"URL Shortner"},{"categories":["tech"],"contents":" FinOps for Data Engineers: Stop Wasting Money by Using Databricks Smarter Databricks has revolutionized how data teams handle big data, machine learning, and analytics by offering a unified cloud platform with powerful distributed computing. But here‚Äôs the tough truth:\nMany companies are burning cloud money unnecessarily because developers are using Databricks notebooks as an all-in-one development environment ‚Äî even for tasks that don‚Äôt need cluster power.\nThis article explores why this behavior is costly, how to shift towards local-first development, and how to use the Databricks CLI to push only the final, distributed workloads to the cloud ‚Äî saving your company potentially thousands of dollars per month.\nThe Problem: Notebooks as IDE = Unnecessary Cloud Costs Notebooks are popular because they‚Äôre interactive, visual, and easy to use. But here‚Äôs what‚Äôs happening across many teams:\nA developer wants to write a small Spark script. They open a Databricks notebook. The cluster spins up. They write some test code, fix syntax errors, retry, debug, iterate. They run small test datasets (which could easily fit on a laptop). They hit an error or need to fix logic, rerun, reconsume cluster time. Every minute the cluster runs, the company is paying for cloud compute, often for work that doesn‚Äôt need distributed resources. Multiply that by dozens or hundreds of engineers, and you‚Äôre staring at runaway Databricks bills.\nThe FinOps Shift: Local-First Development \u0026#43; Cloud-Only Final Runs Here‚Äôs the FinOps-aware workflow we recommend:\n‚úÖ Step 1: Develop locally\nWrite, debug, and unit-test your Spark/PySpark/Scala code on your laptop. Use tools like:\nLocal Jupyter Notebooks or JupyterLab VS Code or PyCharm with Spark dependencies Small local sample datasets This costs you zero cloud dollars.\n‚úÖ Step 2: Use Databricks CLI for Final Cloud Runs\nOnce your code works locally, push it to Databricks clusters only when you need distributed power ‚Äî i.e., when running on full datasets, leveraging Spark parallelism, or integrating with cloud-specific tools.\nDatabricks CLI Setup and Usage Here‚Äôs how to set up the Databricks CLI and integrate it into your local-to-cloud workflow.\n1Ô∏è‚É£ Install the Databricks CLI\nFirst, install the CLI:\n1 pip install databricks-cli 2Ô∏è‚É£ Configure the CLI\nYou need a Databricks personal access token. Generate it in your Databricks workspace (Account Settings ‚Üí User Settings ‚Üí Access Tokens).\nThen configure the CLI:\n1 databricks configure --token You‚Äôll be prompted for: ‚Ä¢\tDatabricks host (e.g., https://.databricks.com) ‚Ä¢\tAccess token\n3Ô∏è‚É£ Use the CLI to Manage Jobs and Notebooks\nUpload local notebook or script 1 databricks workspace import ./my_notebook.py /Users/yourname/my_notebook.py Run a job on Databricks You can define a job JSON file (job-config.json) like: 1 2 3 4 5 6 7 8 9 10 11 { \u0026#34;name\u0026#34;: \u0026#34;my-test-job\u0026#34;, \u0026#34;new_cluster\u0026#34;: { \u0026#34;spark_version\u0026#34;: \u0026#34;13.3.x-scala2.12\u0026#34;, \u0026#34;node_type_id\u0026#34;: \u0026#34;i3.xlarge\u0026#34;, \u0026#34;num_workers\u0026#34;: 2 }, \u0026#34;notebook_task\u0026#34;: { \u0026#34;notebook_path\u0026#34;: \u0026#34;/Users/yourname/my_notebook.py\u0026#34; } } Then trigger the job: 1 databricks jobs create --json-file job-config.json Monitor job runs 1 2 databricks runs list databricks runs get --run-id \u0026lt;run-id\u0026gt; Export results or logs 1 databricks fs cp dbfs:/path/to/results ./local_results --recursive Benefits of Local \u0026#43; CLI Workflow ‚úÖ Cost Savings You avoid paying cloud cluster costs for development/debugging iterations.\n‚úÖ Faster Feedback Local testing gives you immediate feedback without cluster spin-up delays.\n‚úÖ Cleaner Code You push only working, tested code to the cluster, reducing failed runs.\n‚úÖ FinOps Culture Your team builds a culture of cloud cost awareness ‚Äî a key competitive advantage as cloud spend grows.\nFinal FinOps Advice - The Conclusion Databricks is powerful ‚Äî but with great power comes great responsibility (and costs).\nBy adopting a local + CLI workflow, your team can cut waste on iterations, accelerate development, and build a FinOps-aware engineering culture that respects cloud budgets.\nStart today: install the Databricks CLI, shift development locally, and watch your cloud bills drop ‚Äî without sacrificing innovation or speed.\nIf you want, I can also help draft a companion GitHub repo with sample scripts and CLI configs to share with your readers. Would you like that?\n","date":"May 06","description":"FinOps for Data Engineers: Stop Wasting Money by Using Databricks Smarter","permalink":"https://blog.devutkarsh.com/finops-101-saving-databricks-cost/","tags":["databricks","finops","cloud"],"title":"FinOps 101 - Saving Databricks Cost"},{"categories":["tech","cloud"],"contents":"This is not just a tech blog but a story behind as well. I recently switched my job and moved from AWS to Azure at workplace. Also, I am exploring GCP for my personal stuff. Still I don\u0026rsquo;t know enough to choose a personal favorite. üòã\nWhat\u0026amp;rsquo;s your biggest skill? The most interesting question I ever had in any interview is, \u0026ldquo;What drives you to be a better engineer?\u0026rdquo; To which my never changing thought is I am a curious person. I like exploring out in the wild while trekking or diving deep in System32 tinkering with DLL\u0026rsquo;s to make things work my way. It all goes back to highschool when I revamped Windows XP and made my first static website. All because of Curiosity!\n","date":"Feb 05","description":"How life changes with the multiple cloud engineering experience.","permalink":"https://blog.devutkarsh.com/the-story-of-multi-cloud/","tags":["os"],"title":"The story of Multi-Cloud!"},{"categories":["tech"],"contents":" Using Nginx on Kubernetes as a Load Balancer Service with YAML Manifests As the adoption of Kubernetes continues to grow, many of us are looking for robust solutions to manage load balancing within our clusters. Nginx, a powerful and flexible web server, is a popular choice for this purpose. In this post, we\u0026rsquo;ll explore how to use Nginx as a load balancer service on Kubernetes using YAML manifests, avoiding the complexity of Helm, and making it understandable that how nginx works. We\u0026rsquo;ll also cover how to set up SSL certificates using secrets and configure an ingress resource.\nPrerequisites Before we dive in, ensure you have the following:\nA running Kubernetes cluster. kubectl configured to interact with your cluster. An SSL certificate and its corresponding key. Basic understanding of Nginx and it\u0026rsquo;s uses DNS config and SSL certificates Step 1: Create a Namespace We\u0026rsquo;ll start by creating a namespace to isolate our Nginx resources.\n1 2 3 4 apiVersion: v1 kind: Namespace metadata: name: nginx-load-balancer Apply this manifest with:\n1 kubectl apply -f namespace.yaml Step 2: Create a Secret for SSL Certificate Store your SSL certificate and key in a Kubernetes secret. Can be generated using Let\u0026rsquo;s Encrypt.\n1 2 3 4 5 6 7 8 9 apiVersion: v1 kind: Secret metadata: name: tls-secret namespace: nginx-load-balancer type: kubernetes.io/tls data: tls.crt: \u0026lt;base64-encoded-cert\u0026gt; tls.key: \u0026lt;base64-encoded-key\u0026gt; Encode your certificate and key using:\n1 2 base64 -w 0 \u0026lt; your_certificate.crt base64 -w 0 \u0026lt; your_key.key Replace and with the encoded values. Apply the secret manifest:\n1 kubectl apply -f ssl-secret.yaml Remember to update the TXT records for SSL challenge in your DNS provider settings.\nStep 3: Deploy Nginx Deployment Deploy Nginx as a pod within your cluster, which is a nginx controller and allows routing to diffrent services.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment namespace: nginx-load-balancer spec: replicas: 2 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:latest ports: - containerPort: 80 - containerPort: 443 Apply the deployment:\n1 kubectl apply -f deployment.yaml Step 4: Expose Nginx with a Service Create a service to expose Nginx pods. This is of type Load Balancer and on listing k8s services, you will get a public IP which becomes the entry point for all other services.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 apiVersion: v1 kind: Service metadata: name: nginx-service namespace: nginx-load-balancer spec: selector: app: nginx ports: - protocol: TCP port: 80 targetPort: 80 - protocol: TCP port: 443 targetPort: 443 type: LoadBalancer Apply the service:\n1 kubectl apply -f service.yaml Step 5: Configure Ingress Resource Define an ingress resource to route traffic to your Nginx service, leveraging the SSL certificate stored in the secret.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: nginx-ingress namespace: nginx-load-balancer annotations: nginx.ingress.kubernetes.io/ssl-redirect: \u0026#34;true\u0026#34; spec: tls: - hosts: - your-domain.com secretName: tls-secret rules: - host: your-domain.com http: paths: - path: / pathType: Prefix backend: service: name: nginx-service port: number: 80 Replace your-domain.com with your actual domain name. Apply the ingress manifest:\n1 kubectl apply -f ingress.yaml Remember to update the A Record in your DNS provider settings to redirect traffic to the Load Balancer IP.\nEureka By following these steps, you\u0026rsquo;ve successfully set up Nginx as a load balancer on Kubernetes using YAML manifests. This approach provides a straightforward method to manage your configuration, ensuring a clear and maintainable deployment process. Feel free to tweak these manifests to fit your specific use case, and happy deploying!\n","date":"Jul 22","description":"NGINX on Kubernetes as a Load Balancer \u0026 Ingress","permalink":"https://blog.devutkarsh.com/nginx-on-kubernetes/","tags":["kubernetes","nginx","load balancer","ingress"],"title":"NGINX on Kubernetes"},{"categories":["tech"],"contents":"\nAchieving No Downtime in Kubernetes Deployments Introduction Kubernetes is a powerful container orchestration platform that enables the deployment, scaling, and management of containerized applications. When deploying applications in a production environment, minimizing downtime is crucial to ensure a seamless user experience. In this article, we will explore strategies and best practices to achieve zero or minimal downtime during Kubernetes deployments.\n1. Rolling Deployments One of the fundamental features of Kubernetes is rolling deployments. Kubernetes supports updating a service by gradually replacing instances of the old application with the new one. This ensures that a portion of your application is always available, reducing downtime.\nExample Deployment: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 apiVersion: apps/v1 kind: Deployment metadata: name: sample-app spec: replicas: 3 selector: matchLabels: app: sample-app template: metadata: labels: app: sample-app spec: containers: - name: sample-app image: your-registry/sample-app:latest Apply changes:\n1 kubectl apply -f updated-deployment.yaml Kubernetes will gradually replace pods, ensuring a smooth transition.\n2. Readiness Probes Use readiness probes to delay traffic until the application is ready to serve. This prevents routing requests to instances that are not yet fully operational.\nExample Readiness Probe: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 apiVersion: v1 kind: Pod metadata: name: sample-app spec: containers: - name: sample-app image: your-registry/sample-app:latest readinessProbe: httpGet: path: /healthz port: 8080 initialDelaySeconds: 5 periodSeconds: 5 This configuration checks the /healthz endpoint and delays traffic until the probe succeeds.\n3. Horizontal Pod Autoscaling Automatically adjust the number of pod replicas based on CPU or memory usage. This helps maintain performance and availability under varying loads.\nExample Horizontal Pod Autoscaler: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 apiVersion: autoscaling/v2beta2 kind: HorizontalPodAutoscaler metadata: name: sample-app-autoscaler spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: sample-app minReplicas: 2 maxReplicas: 5 metrics: - type: Resource resource: name: cpu targetAverageUtilization: 80 This example scales the number of replicas based on CPU usage, ensuring your application can handle increased demand.\n4. Blue-Green Deployments Implementing a blue-green deployment strategy involves running two identical environments ‚Äì blue (current) and green (new). Switching between them is a matter of updating the routing configuration.\nExample Service Switch: 1 2 3 4 5 6 7 8 9 10 11 apiVersion: v1 kind: Service metadata: name: sample-app spec: selector: app: sample-app-blue # or sample-app-green ports: - protocol: TCP port: 80 targetPort: 8080 Update the service to switch between blue and green deployments.\n1 kubectl apply -f updated-service.yaml Conclusion Minimizing downtime in Kubernetes deployments involves careful planning and leveraging the platform\u0026rsquo;s features. Rolling deployments, readiness probes, horizontal pod autoscaling, and blue-green deployments are powerful tools to ensure a seamless user experience. Combining these strategies allows you to deploy updates with confidence, knowing that your application remains available and responsive. As you navigate the world of Kubernetes deployments, always test changes in staging environments before applying them to production to catch potential issues early in the development lifecycle.\n","date":"Dec 29","description":"How to prevent service downtime in kubernetes","permalink":"https://blog.devutkarsh.com/no-downtime-for-microservices/","tags":["kubectl","microservice","kubernetes"],"title":"No downtime for microservices"},{"categories":["tech"],"contents":"\nWhat is edge authentication? Edge authentication or authorization is a way to validate all the requests before they reach the actual microservice or private networks i.e. at the edge. This is done at a global level for all the services, so that individual microservice do not have to handle the authentication or authorization on thier own. This removes the security overhead from all microservices so that they can communicate insecurely in the mesh within a private network and focus on only concerned business logic.\nA JWT Token is generated at the edge using username \u0026amp; password after a Single Factor Authentication (SFA) in this demo, as in the diagram above. The JWT token is then used in all the subsequent API calls which are validated and authorized at a L7 reverse proxy service like nginx or netflix zuul or spring gateway. Once the token is validated and route access is authorized, the claims from the JWT are decoded and added to the header before passing to the downstream services.\nThis provides us 5 core benefits -\nThe internal microservice communication happens based on headers insecurely, cutting down on the latency due to multiple auth calls, and overhead for implementation logic. All auth logic remains at the edge and reduces the coupling and cyclic dependencies from other microservices. This is futuristic for upgrades if you want to move from SFA to MFA. With reverse proxy, all communication between downstream microservices can be based on the headers only and does not need a token or auth mechanism. No binding of Spring security and roles in code. Instead we utilize Rego Rules from OPA. Hence removing cross-cutting concerns for authorization. For this session we will focus only on how to build a Edge Auth service in SFA. How to generate a JWT token and the JWKS WebKey Sets using Java. We will utilize auth0 for JWT and nibus-jose libraries for JWKS KeySet. This turns the edge-auth service to behave like a ID server.\nIn the images added above we have a gateway, which exposes 2 public endpoints -\n/login is exposed to get username password and on successful authentication responds with a JWT token and claims like username and user-type. /.well-known/jwks.json is a public JSON WebSet Keys endpoint which has public key to verify and validate the token which is signed with it\u0026rsquo;s corresponding private key. This can be used if any external service wants to verify the authenticity of your token. Mostly the JWKS endpoints are public for external services to verify the token whenever required. Then there is a private endpoint which is token hungry -\n/validate - This is to also to Authenticate token but most importantly Authorize and validate whether a requested endpoint or URL with a valid token is allowed access to the user based on it\u0026rsquo;s user-type. This is controlled using the Open Policy Agent or say OPA. So a user with user-type admin should be open to all admin API\u0026rsquo;s but a normal user like a customer should not be allowed to access the admin API. This is controlled using Open Policy Agent and rego rules. Let\u0026rsquo;s see how to develop the authentication module first -\nThe Auth controller for login module and generates JWT token after validating username password. Also, we have the validation endpoints where we generate the JWKS endpoint. And a valiate endpoint for authorization, which we will cover later.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 @RestController @RequestMapping(\u0026#34;/\u0026#34;) @Slf4j public class AuthController { @Autowired AuthOperations authOperations; @PostMapping(\u0026#34;/login\u0026#34;) public ResponseEntity\u0026lt;String\u0026gt; login(@RequestBody HashMap\u0026lt;String, String\u0026gt; credentials) { log.info(\u0026#34;Login Controller..\u0026#34;); // call some real validation API with credentials return new ResponseEntity\u0026lt;\u0026gt;(authOperations.generateToken(), HttpStatus.OK); } @GetMapping(\u0026#34;/.well-known/jwks.json\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; jwksEndpoint() { log.info(\u0026#34;JWKS keyset Controller..\u0026#34;); HttpHeaders responseHeaders = new HttpHeaders(); responseHeaders.set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;); return new ResponseEntity\u0026lt;\u0026gt;(authOperations.jwksKeySet(), responseHeaders, HttpStatus.OK); } @PostMapping(\u0026#34;/validate\u0026#34;) public ResponseEntity\u0026lt;Boolean\u0026gt; validate(@RequestBody HashMap\u0026lt;String, String\u0026gt; requestTokenAndUri) { log.info(\u0026#34;Authorization token Controller..\u0026#34;); return new ResponseEntity\u0026lt;Boolean\u0026gt;(authOperations.authorize(requestTokenAndUri), HttpStatus.OK); } } The underlying service operations would be the logic on how to generate a token. We are using the public and private RSA keys for this example. We can store the private key in application.yml also. But for this example we will generate them dynamically.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 @Component @Slf4j public class AuthOperations { @Autowired KeysGenerator keys; @Value(\u0026#34;${server.port}\u0026#34;) private String serverPort; UUID kid = UUID.randomUUID(); public String generateToken() { String token = null; try { PrivateKey privateKey = (PrivateKey) keys.getRSAKeys(KeysGeneratorStrategy.DYNAMIC).get(AuthConstants.PRIVATE_KEY); Date today = new Date(); Calendar c = Calendar.getInstance(); c.setTime(today); c.add(Calendar.DATE, 1); Date tomorrow = c.getTime(); token = Jwts.builder() .setHeaderParam(\u0026#34;kid\u0026#34;, kid) .setId(UUID.randomUUID().toString()) .setIssuedAt(today) .setSubject(\u0026#34;tester\u0026#34;) .setIssuer(\u0026#34;localhost\u0026#34;) .setExpiration(tomorrow) .signWith(privateKey) .compact(); log.info(\u0026#34;Token generated\u0026#34;); } catch (Exception e) { log.error(\u0026#34;Cannot generate token\u0026#34;, e.getMessage()); } return token; } @Cacheable public Map\u0026lt;String, List\u0026lt;JSONObject\u0026gt;\u0026gt; jwksKeySet() { try { PublicKey publicKey = (PublicKey) keys.getRSAKeys(KeysGeneratorStrategy.DYNAMIC).get(AuthConstants.PUBLIC_KEY); JWK jwk = new RSAKey.Builder((RSAPublicKey) publicKey) .keyUse(KeyUse.SIGNATURE) .keyID(kid.toString()) .build(); Map\u0026lt;String, List\u0026lt;JSONObject\u0026gt;\u0026gt; keyset = new HashMap\u0026lt;String, List\u0026lt;JSONObject\u0026gt;\u0026gt;(); List\u0026lt;JSONObject\u0026gt; keys = new ArrayList\u0026lt;JSONObject\u0026gt;(); keys.add(jwk.toJSONObject()); keyset.put(\u0026#34;keys\u0026#34;, keys); return keyset; } catch (Exception e) { log.error(\u0026#34;Cannot generate JWKS keyset\u0026#34;, e.getMessage()); } return null; } public Boolean authorize(String request) { // logic for OPA. JWT token and URI validation } } Beside the service is the core logic for dynamic RSA keys generation. Here we have 2 strategies to load the private keys, which is defined using the enum. We can read the private key from the file (recommended in case of microservices) and dynamically (just for this example).\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 @Component @Slf4j public class KeysGenerator { public enum KeysGeneratorStrategy{ FILE, DYNAMIC } @Value(\u0026#34;${keys.private}\u0026#34;) private String privateKeyString; Map\u0026lt;String, Object\u0026gt; keys; public Map\u0026lt;String, Object\u0026gt; getRSAKeys(KeysGeneratorStrategy strategy) { if (null == keys) { keys = genrateRSAKeys(strategy); return keys; } if (keys.size() \u0026gt; 0) { return keys; } else { keys = genrateRSAKeys(strategy); return keys; } } @Cacheable public Map\u0026lt;String, Object\u0026gt; genrateRSAKeys(KeysGeneratorStrategy strategy) { try { log.info(\u0026#34;Generating New Keys {}\u0026#34;, strategy); if(strategy.equals(KeysGeneratorStrategy.FILE)){ PrivateKey privateKey = getPrivateKey(); PublicKey publicKey = getPublicKey(privateKey); Map\u0026lt;String, Object\u0026gt; keys = new HashMap\u0026lt;String, Object\u0026gt;(); keys.put(AuthConstants.PRIVATE_KEY, privateKey); keys.put(AuthConstants.PUBLIC_KEY, publicKey); log.info(\u0026#34;Keys Added Successfully\u0026#34;); return keys; } if(strategy.equals(KeysGeneratorStrategy.DYNAMIC)){ KeyPairGenerator keyPairGenerator = KeyPairGenerator.getInstance(AuthConstants.KEYPAIR_GENERATOR_ALGORITHM); keyPairGenerator.initialize(2048); KeyPair keyPair = keyPairGenerator.generateKeyPair(); PrivateKey privateKey = keyPair.getPrivate(); PublicKey publicKey = keyPair.getPublic(); Map\u0026lt;String, Object\u0026gt; keys = new HashMap\u0026lt;String, Object\u0026gt;(); keys.put(AuthConstants.PRIVATE_KEY, privateKey); keys.put(AuthConstants.PUBLIC_KEY, publicKey); log.info(\u0026#34;Keys Generated Successfully\u0026#34;); return keys; } return null; } catch (Exception e) { log.error(\u0026#34;Cannot generate RSA keys {}\u0026#34;, e); return null; } } public PublicKey getPublicKey(PrivateKey privateKey){ try{ RSAPrivateCrtKey privk = (RSAPrivateCrtKey) privateKey; RSAPublicKeySpec publicKeySpec = new java.security.spec.RSAPublicKeySpec(privk.getModulus(), privk.getPublicExponent()); KeyFactory keyFactory = KeyFactory.getInstance(\u0026#34;RSA\u0026#34;); PublicKey publicKey = keyFactory.generatePublic(publicKeySpec); return publicKey; }catch(Exception e){ log.error(\u0026#34;Cannot read public key {}\u0026#34;, e); return null; } } public PrivateKey getPrivateKey(){ try{ log.info(\u0026#34;Read key {}\u0026#34;, privateKeyString); byte[] keyBytes = privateKeyString.getBytes(); PKCS8EncodedKeySpec spec = new PKCS8EncodedKeySpec(keyBytes); KeyFactory kf = KeyFactory.getInstance(\u0026#34;RSA\u0026#34;); return kf.generatePrivate(spec); }catch(Exception e){ log.error(\u0026#34;Cannot read private key {}\u0026#34;, e); return null; } } } Now on running the application we can see, we are able to generate the token. You can execute following curl command -\n1 2 3 4 5 6 curl --location --request POST \u0026#39;http://localhost:8080/login\u0026#39; \\ --header \u0026#39;Content-Type: application/json\u0026#39; \\ --data-raw \u0026#39;{ \u0026#34;username\u0026#34;:\u0026#34;test\u0026#34;, \u0026#34;password\u0026#34;:\u0026#34;test\u0026#34; }\u0026#39; Your output would be similar to this - Also the JWKS endpoint will return the JSON webset keys with following curl command -\n1 curl --location --request GET \u0026#39;http://localhost:8080/.well-known/jwks.json\u0026#39; The output would be similar to this - The authentication source code is available on github where you can explore the The Authorization - Part 2 flow we will be covering in next tutorial along with basics about Open Policy Agent. This whole edge auth module will also be a used in an upcoming tutorial for istio and it\u0026rsquo;s benefits in kubernetes.\nAlso, we are trying to build the edge-auth as a generic container image for secure system communications in a microservice architecture. If you like building stuff and want to work on FOSS projects feel free to reach out and contribute to the project.\n","date":"Jul 03","description":"Single Factor Authentication in Java microservice using JWT token and JWKS KeySet validation.","permalink":"https://blog.devutkarsh.com/edge-auth-authentication-part-1/","tags":["microservice","java","security"],"title":"Edge Auth - Authentication - Part 1"},{"categories":["tech"],"contents":" Setting up Istio Service Mesh on Kubernetes Getting a kubernetes cluster up and running is fairly easy now. But I\u0026rsquo;ve seen challenges like -\nHow to moinitor the network flow \u0026amp; health? How to ingress traffic is microservices ? How to do canary deployments \u0026amp; prevent downtimes? How to perform Auth on incoming requests? Then I came across this amazing service-mesh bundle for my infrastucture layer specially made for distributed systems running on Kubernetes. Kuberentes has made container orchestration a cake and then istio is the cherry on the cake that all DevOps need!\nTo get started you must have a kubernetes cluster running. You can follow how to create a kubernetes cluster on AWS EKS or a minikube in your local docker setup.\nSetting up the Istio Service Mesh Download and install istioctl command line 1 curl -L https://istio.io/downloadIstio | sh - This will download the package into your local download location.\nGo into the download istio package and set the bin path so that you can execute the istioctl commands cd istio-{version} export PATH=$PWD/bin:$PATH Now your istioctl command line tool should be ready. Run the below command to setup istio to your kubernetes. Istio will be installed in it\u0026rsquo;s seperate namespace. istioctl install --set profile=demo -y Note : Make sure the correct kubernetes cluster context is set before you install istio.\nAlso the more better way is to generate the manifests.yaml which can be used with kubectl so that you don\u0026rsquo;t have to install istio shell when migrating to different environments. Manifests are easy to configure and migrate using Kustomize.\nNow once istioctl commands have executed successfully, you can setup a label to all your k8s deploymetns under default namespace. This would be used by istio to inject a side car proxy and monitor the running pods and services in the cluster. kubectl label namespace default istio-injection=enabled Now you will have a envoy side car proxy service running alongside all your pods.\nTo check if istio side car proxy is in place describe the pod and you will see 2 container are running. As of June 2022, if you are on Apple Silicon M1 chip, and facing issues related to iptables in istio-init container, take a look at following way to install istio - Istio on Apple MacOS M1 workaround..\nNow when you have your istio side cars up and running. We will see the benefits on istio in routing traffic and canary depolyments.\n","date":"Jun 24","description":"Routing, Gateway and basic telemetry with Istio Service Mesh in Kubernetes cluster","permalink":"https://blog.devutkarsh.com/istio-service-mesh-in-kubernetes/","tags":["istioctl","kubectl","microservice","kubernetes","istio"],"title":"Istio service mesh in kubernetes"},{"categories":["travel"],"contents":" Of all the India that I‚Äôve seen, this was different. This was when first wave of Corona was over and things were at ease. So I left home to be in the remotest from where I can work peacefully. All those months in lockdown were really depressing and I felt to the core how it feels to be caged. Well I wanted to be free and so I took a one way ticket to Siliguri. From there I went to Darjeeling to break my journey.\nThe main town in Darjeeling is good to stay and chiil but it is small place to explore. Since I was working from Hide Out Darjeeling, a cozy bagpacking hostel. After my one week stay I moved to Gangtok.\nNever seen a city so civilised and clean - Gangtok Gangtok seemed like it belongs to another country and isn\u0026rsquo;t affected by the typical Indian mindset. I was so impressed, the way it was clean, people taking footover bridges to cross roads. My biggest surprise was no unnecessary honking. People seemed free, independent and thriving in the best atmosphere. I stayed in Tag Along Bagpackers. A very well maintained travelers hostel and Travel Cafe ran by few childhood friends.\nTravel Cafe at TagAlong Bagpackers, Gangtok\nTravel Cafe was one such place where I was chilling almost all the time. Thanks to Sharan for keeping the music and the vibe alive, I didn\u0026rsquo;t needed my headphone while working here. I fell in love with this song, A Different Age by Current Joys. The weather was so chilling in winters here and I was working with some amazing streaming code snippet.\nThe walk to amazing Mall Road was mesmerizing.\nTo be continued.\n","date":"Jan 14","description":"I was working remotely in the mountains.","permalink":"https://blog.devutkarsh.com/a-month-of-bagpacking-in-sikkim/","tags":["sikkim","remote","digital nomad"],"title":"A month of bagpacking in Sikkim"},{"categories":["tech"],"contents":" Kubernetes Configuration Management for DEV, Staging, QA, Production, etc - So you may have learned so far how to set up a kuberentes cluster and how to write a manifest and then deploy a pod out of it. If not please refer to my post on getting started with kuberenetes manifests. But you may still be puzzled about how to configure it for multiple environments. Yes, it is possible to use a single deployment and service template to be used for multiple environments. This is needed because all your application configs and environment variables will differ with the different environment like DEV, Staging, QA, and Production. To do this we will leverage Kustomize, a native of kubectl CLI used for configuration management.\nSo we have got a little project structure where we are going to put manifests for some apps as bases and refer them for building and deploying them in our dev and staging environment.\nHere we have a root apps folder that contains service-bases and environment sub-folder. service-bases folder is used to keep our template or base manifest yaml files that define what our deployments should look like irrespective of environment. So we have created an app folder named s3-streamer in services-bases and have put all your deployment.yaml and service.yaml files. Along with the yaml manifest, there is one extra file that you see here named as kustomization.yaml which tells what are resources are present at the current directory location.\n1 2 3 4 5 6 apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - deployment.yaml - service.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 apiVersion: apps/v1 kind: Deployment metadata: name: s3-streamer namespace: default spec: replicas: 1 #this will be overridden based on environment selector: matchLabels: app: s3-streamer template: metadata: labels: app: s3-streamer spec: containers: - name: s3-streamer image: devutkarsh/s3-streamer ports: - containerPort: 9999 1 2 3 4 5 6 7 8 9 10 11 12 apiVersion: v1 kind: Service metadata: name: s3-streamer spec: selector: app: s3-streamer type: ClusterIP ports: - name: http port: 9999 targetPort: 9999 This defines our bases.\nNow in our environment folder, we have our 2 deployment environments say dev and staging so we have 2 folders respectively for them. In each environment folder (i.e. dev and staging), we will create a similar app folder again and have a kustomization.yaml. But this is an overlay that will be used to patch the templates that we defined in our bases.\nTo demonstrate this, we want different replica counts of our pods based on our environment. In dev we want just 3 pods while in staging we might need 6. So we will refer to the base template of the app and patch the required settings.\nA setting to be patched would look like this for dev environment -\n1 2 3 4 5 6 apiVersion: apps/v1 kind: Deployment metadata: name: s3-streamer spec: replicas: 3 #this will change in staging While patching this, we will need our kustomization.yaml which is an overlay and defines where to look for base settings, how to patch the new settings. Which is defined as below -\n1 2 3 4 5 6 7 8 apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization bases: - ../../../service-bases/s3-streamer patchesStrategicMerge: - replica-count.yaml Similarly both files we have in our staging also, but with different replica counts.\nTo apply these settings for our dev environment we will run -\nkubectl -k environment/dev/s3-streamer To apply these settings for our staging environment we will run -\nkubectl -k environment/staging/s3-streamer So for both environments, bases are the same but we have patched the replica count based on the environment.\nYou can refer to the project structure on my git here.\nNote : If you are going to apply the manifest manually for different environments, it is very much prone to manual error of not switching the cluster context while performing the deployment and accidentally deploying in the wrong cluster or environment.\nTo overcome the above problem, it is advisable to use a continuous deployment pipeline that can look for your changes in manifest and deploy it for you in the cluster, instead of you doing it manually. The best in the market for implementing CD are ArgoCD and FluxCD as of 2021. I will write a blog on that too but some other time.\n","date":"Sep 26","description":"Multiple environments (DEV, Staging, QA, Prod) with Kubernetes and Kustomize","permalink":"https://blog.devutkarsh.com/configuring-kubernetes-for-multiple-environments-with-kustomize/","tags":["kubectl","microservice","kubernetes","kustomize"],"title":"Configuring Kubernetes for Multiple Environments with Kustomize"},{"categories":["tech"],"contents":" Deploy your first container on Kuberentes cluster Well if you have followed us on the previous blog post on how to create a kubernetes cluster on AWS EKS or have gone with local kubernetes clusters like minikube etc. Then you must be aware that to manage all the resources \u0026amp; objects on your cluster you will need a command-line tool kubectl which interacts on your behalf with the kube-api-server to perform almost all operations on your cluster.\nWhat are deployments and pods? A deployment can be understood as a template that defines how your actual running container will look based on the specifications provided. Each actual running container is built from the deployment specified and is termed as a pod. A sample deployment will look like below -\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 apiVersion: apps/v1 kind: Deployment metadata: name: s3-streamer namespace: default spec: replicas: 1 selector: matchLabels: app: s3-streamer # used by deployment template: metadata: labels: app: s3-streamer # used for marking pods spec: containers: - name: s3-streamer image: devutkarsh/s3-streamer #image hosted on docker hub ports: - containerPort: 9999 This is a deployment manifest for a microservice named s3-streamer written on Java to stream AWS S3 objects into the cluster. More details about the service can be found here.\nTo apply this deployment you can go to the saved directory of above yaml file and run the following command in your OS terminal-\n1 kubectl apply -f deployment.yaml And see a similar output -\ndeployment.apps/s3-streamer created Then you can run commands to get deployment and pods to see them running status -\n1 2 3 4 5 6 devutkarsh@ud s3-streamer % kubectl get deployment NAME READY UP-TO-DATE AVAILABLE AGE s3-streamer 1/1 1 1 19m devutkarsh@ud s3-streamer % kubectl get pods NAME READY STATUS RESTARTS AGE s3-streamer-78779d7c85-j7clz 1/1 Running 0 19m You can further run describe commands on your resources to understand more on what\u0026rsquo;s happening by running - kubectl describe pod s3-streamer-78779d7c85-j7clz\nWhat\u0026rsquo;s important to note here is that there can be multiple pods running for the same deployment based on the replica count set, which comes in handy in the case of load distribution and canary deployments. Also, another important point to note down here is that this application running on port 9999 is just like a black box and has no cluster endpoint assigned to it. So it will not be accessible over the network, but can only be accessed by port-forwarding the pod or deployment directly as of now. Each pod will have its random IP which we can\u0026rsquo;t guess because pods are volatile.\nWhat is a Service? As stated in the note above that the deployed pods will not be accessible over the cluster network because they have no known IP assigned (but some random IPs based on your cluster CIDR block). This is exactly the problem that a service solves for you. It assigns a specific cluster DNS endpoint to your deployment and then all the pods that are running for that particular deployment are load-balanced under a single DNS name in a round-robin fashion. This all networking is taken care of by kube-proxy agent on your cluster.\n1 2 3 4 5 6 7 8 9 10 11 12 apiVersion: v1 kind: Service metadata: name: s3-streamer spec: selector: app: s3-streamer type: ClusterIP ports: - name: http port: 9999 targetPort: 9999 To apply this service run the following command in your OS terminal -\n1 kubectl apply -f service.yaml And see a similar output -\nservice/s3-streamer created Then you can run commands to get or describe your service to see the status -\n1 2 3 devutkarsh@ud s3-streamer % kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE s3-streamer ClusterIP 10.105.14.47 \u0026lt;none\u0026gt; 9999/TCP 29s Now this service is configured with a cluster IP. Also, the application would be available at http://service-name:port-number/ i.e. http://s3-streamer:9999/. We can also get an external IP attached, but we will see that some other time.\nThe bridge in between The deployment is an independent resource and so is the service. So we need to make sure that both are intertwined, which is taken care of by the label in deployment.yaml and selector in service.yaml. In this way, the provided selector app=s3-streamer in service yaml knows that it needs to take care of all the pods with the same labels while load balancing.\nTo test this we will create a throw-away pod using busy box docker image with curl utility installed and bash right into its shell -\n1 kubectl run curl-test --image=radial/busyboxplus:curl -i --tty --rm Then run curl command, keep the output handy and exit the pod. -\n1 2 3 4 5 6 7 8 9 [ root@curl-test:/ ]$ curl -I http://s3-streamer:9999/abc/xyz HTTP/1.1 400 Content-Length: 0 Date: Fri, 24 Sep 2021 19:44:01 GMT Connection: close [ root@curl-test:/ ]$ exit Session ended, resume using \u0026#39;kubectl attach curl-test -c curl-test -i -t\u0026#39; command when the pod is running pod \u0026#34;curl-test\u0026#34; deleted This resulted in a 400 status error because it was looking for an AWS S3 bucket abc with object key xyz which is not present, but we know that we were able to trigger the service communication at least.\nTo verify that s3-streamer service was invoked using the DNS assigned on the local cluster network from inside of our throw-away pod, we will take a look at the logs generated by s3-streamer service as pasted below. To confirm we can see line number 27 in the output -\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 devutkarsh@ud s3-streamer % kubectl get pods NAME READY STATUS RESTARTS AGE s3-streamer-f8585b8cc-c8rvb 1/1 Running 0 12m devutkarsh@ud s3-streamer % kubectl logs s3-streamer-f8585b8cc-c8rvb . ____ _ __ _ _ /\\\\ / ___\u0026#39;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\ ( ( )\\___ | \u0026#39;_ | \u0026#39;_| | \u0026#39;_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) \u0026#39; |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.4.3) 2021-09-24 19:37:02.515 INFO 1 --- [ main] com.s3streamer.Init : Starting Init using Java 1.8.0_212 on s3-streamer-f8585b8cc-c8rvb with PID 1 (/s3-streamer-0.0.1-SNAPSHOT/lib/s3-streamer-0.0.1-SNAPSHOT.jar started by root in /) 2021-09-24 19:37:02.521 INFO 1 --- [ main] com.s3streamer.Init : No active profile set, falling back to default profiles: default 2021-09-24 19:37:05.322 INFO 1 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 9999 (http) 2021-09-24 19:37:05.345 INFO 1 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat] 2021-09-24 19:37:05.346 INFO 1 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.43] 2021-09-24 19:37:05.505 INFO 1 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext 2021-09-24 19:37:05.506 INFO 1 --- [ main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 2837 ms 2021-09-24 19:37:06.432 INFO 1 --- [ main] o.s.s.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService \u0026#39;applicationTaskExecutor\u0026#39; 2021-09-24 19:37:06.879 INFO 1 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 9999 (http) with context path \u0026#39;\u0026#39; 2021-09-24 19:37:06.917 INFO 1 --- [ main] com.s3streamer.Init : Started Init in 5.631 seconds (JVM running for 6.555) 2021-09-24 19:40:24.830 INFO 1 --- [nio-9999-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring DispatcherServlet \u0026#39;dispatcherServlet\u0026#39; 2021-09-24 19:40:24.830 INFO 1 --- [nio-9999-exec-1] o.s.web.servlet.DispatcherServlet : Initializing Servlet \u0026#39;dispatcherServlet\u0026#39; 2021-09-24 19:40:24.842 INFO 1 --- [nio-9999-exec-1] o.s.web.servlet.DispatcherServlet : Completed initialization in 10 ms Fetching /abc/xyz Error The bucket is in this region: us-east-1. Please use this region to retry the request (Service: Amazon S3; Status Code: 301; Error Code: PermanentRedirect; Request ID: .... You can refer to the yaml\u0026rsquo;s on my GitHub repo as well \u0026ndash;\u0026gt; Kubernetes deployment and service example yaml.\nI will be next writing on how to set up these manifest for better configuration management to support deployment on different environments and support Multiple environments (DEV, Staging, QA, Prod) with Kubernetes and Kustomize\n","date":"Sep 23","description":"How to write a basic deployment and service.","permalink":"https://blog.devutkarsh.com/getting-started-with-kubernetes-manifests/","tags":["kubectl","microservice","kubernetes"],"title":"Getting started with Kubernetes Manifests"},{"categories":["music"],"contents":"A night of September 2018 and some random weekend when I was chilling with my friends at a house party in Bangalore. Most of the weekends (and even weekdays) you will find almost all IT employees here grabbing a drink and catching up with friends or colleagues. So just like everyone else, I was enjoying it too. Though on the other side of the story there was someone waiting for that daily call and I was breaking a habit tonight, which pissed her off. Also, I get bored with mundane. Soon after the party was over and the new day was rising, we went to Nandi Hills to watch the sunrise, again just following what all Bangaloreans do when up awake early. So I was at Nandi Hills when I wrote few lines and turned it into a poerty eventually.\nSoon after it was poetry, I was really moved by the structure it had in the lyrics, enough to add some music and make it a song. Within few months I had a half-baked song with all the chords to get the verse and chorus together. And as usual, it was all scattered in my personal diary, google keep app, and a lot more in my head. Having a very scarce time and almost no music production skills were hindering to let it be a fully produced song.\nThis is the problem as I see it. I don\u0026rsquo;t belong in the music industry and thus have very few people with the same interest to work with. There is a huge sea to cross, from where you are and where you want to be.\nSo then here was 2020, a time in itself in which I invested carefully in brushing up on production skills while staying indoors. If this pandemic would not have happened, I would have probably quit my job in IT and have gone out to be a full-time traveler (just another lifestyle I would love to live). But this is the beauty with time, it comes with maturity if you are ready to learn from all your past mistakes. Eventually, I prepared a scratch with my very very basic music production skills and shared it with Ankit to have a look and convert it into a neat art, which he does as always!\nYou can find the link to your favorite music platform for the song here on Kisi Subah\n","date":"Sep 17","description":"Are you telling people often that why you love them?","permalink":"https://blog.devutkarsh.com/kisi-subah/","tags":["kisi subah","original song"],"title":"Kisi Subah"},{"categories":["music"],"contents":"It was in 2014 when I had finished my engineering and was looking out for jobs. It was tough time when everything I got felt like was falling apart. As music always have been an amazing savior, came to rescue, and Kho Gaya Hu was born. It took merely 40 minutes to get the music and lyrics. It all just came naturally. I was alone in the flat tinkering with my guitar in hot June afternoon.\nThose were the days when my friends were telling me how to prepare a good resume, my dad asked to prepare for government jobs and I had just quit an intern position at a startup, after 5 days at work, as they weren\u0026rsquo;t ready to pay well. And here was me, trying to match the harmony on G major. Along with all this, I had to hold onto the broken heart as well. College was over and it seemed like the end of all good moments.\nWhen nothing feels right, and emotions take a toll on me, music is a good way to distract. Being an invtroverted personality, it is always easy for me to express it all in writing. Haha, such a Dear Diary moment!\nIt was fun time too because a lot was going on around with Soul Raaga, a in house recording studio that me and Ankit Godle had started to try an experimental genre Sufi with Electronic music.\nHere is what all the feelings meant back then. You can find the link to your favorite music platform for the song here on Kho Gaya Hu\n","date":"Jul 20","description":"Why just write songs and poetry. I can sing too. ","permalink":"https://blog.devutkarsh.com/kho-gaya-hu/","tags":["kho gaya hu","original song"],"title":"Kho Gaya Hu"},{"categories":["tech"],"contents":" Java spring-boot microservice to read objects from AWS S3 bucket that can be accessed by other microservices over HTTP I recently came across a requirement to host static content for my microservices running on the AWS EKS cluster.\nSince there were multiple services that will be accessing different objects so I thought to create a common S3 bucket for hosting and gave S3ReadAccess to my cluster.\nThis saves effort on the microservices end. No S3 SDK implementation is required. So a microservice accessing any static content on the drive path locally just need to update its application config to point to an HTTP endpoint on deployment.\nAlso, this saves any need to adding persistent volume for static hosting on the cluster.\n1 aws s3api create-bucket --bucket hosting-bucket --region us-east-1 --create-bucket-configuration LocationConstraint=us-east-1 And then I wrote a common microservice named s3Streamer which can be used to read objects from the bucket over HTTP endpoint.\n1 http://s3-streamer:9999/\u0026lt;bucket_name\u0026gt;/\u0026lt;object_key\u0026gt; To deploy this, you can run a simple kubectl command\n1 kubectl apply -f https://github.com/devutkarsh/s3-streamer/blob/master/s3-streamer.yaml If you face any issues, you can take a look at Github file.\n","date":"Jul 12","description":"We don't need Volumes. Host static content on EKS with AWS S3.","permalink":"https://blog.devutkarsh.com/streaming-aws-s3-objects-in-aws-eks-cluster/","tags":["aws","devops","code","microservice"],"title":"Streaming AWS S3 objects in AWS EKS cluster"},{"categories":["tech"],"contents":" Using self-managed Amazon EC2 nodes (No Fargate) To create a kubernetes cluster on aws eks, we would be using the aws cli and eksctl that needs to be installed on your local command line as a pre-requisite.\nYour aws cli should be configured with the access token and secret of your aws console and your user should have right aws IAM access role.\nNow as you have this ready, we will be creating a config file named as cluster.yaml which would be used to setup the cluster as follows -\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 apiVersion: eksctl.io/v1alpha5 kind: ClusterConfig metadata: name: demo-cluster-name region: \u0026#34;eu-central-1\u0026#34; version: \u0026#34;1.19\u0026#34; iam: withOIDC: false managedNodeGroups: - name: demo-cluster-nodegroup-1 iam: attachPolicyARNs: - arn:aws:iam::aws:policy/AmazonS3FullAccess instanceType: t2.small desiredCapacity: 1 volumeSize: 10 ssh: allow: true For this example our cluster name is demo-cluster-name which we are deploying in eu-central-1 region and have defined only one EC2 instance that will be the part of the cluster. Our Ec2 node name is demo-cluster-nodegroup-1 which is of size t2.small with 10GB space as volumeSize.\nTo create this we will run the following command -\neksctl create cluster -f cluster.yaml After the executing will run successfully, your cluster could be seen in AWS EKS service in AWS console or you can run -\neksctl get cluster Your output say EKSCTL CREATED as true for cluster name demo-cluster-name.\n","date":"Jul 10","description":"Kubernetes 101 - Just Getting started.","permalink":"https://blog.devutkarsh.com/how-to-create-a-kubernetes-cluster-on-aws-eks/","tags":["kubernetes","aws eks","eksctl"],"title":"How to create a Kubernetes cluster on AWS EKS"},{"categories":["tech"],"contents":" Merge file parts/chunks in S3 on receive - PUT object by invoking lambda Sending files in chunks over the network is most common because it\u0026rsquo;s easy to apply a retry mechanism over failed parts. On receiving all the parts then the parts or chunks are merged together to create one single file. We all know how frustrating is to see download failing at 99%.\nData chunking is the most common technique used by your wifi to send you data packets. Splitting the data into packets means the data transmission is not as dependent on the availability of the networks on the path. Once the packets are delivered, the sender sends a final confirmation. Say 200 OK!\nIn a common scenario where you receive files in multiple parts in your S3 Bucket instead of a large bulky file, you might need to merge those file parts in real-time.\nThe most effective way to do this using AWS S3 Events to invoke the AWS Lambda function to do the merge process over all the files.\nYou will need a valid S3 bucket, Lambda, and permissions around it as a Pre-requisite.\nYour file coming in parts might be named as -\nfilename_part1.ext filename_part2.ext If any of your systems is generating those files, then use the system to generate a final dummy blank file name as -\nfilename.final Since in your S3 event trigger you can use a suffix to generate an event, use .final extension to invoke lambda, and process records.\nThe event type in S3 should be PUT so that every time a file is PUT using PUT object operation with extension *.final\nSince your event is set, then you need to invoke the target lambda which will receive the S3Event of the records that were put in the S3 bucket.\nThe S3 event structure looks like this -\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 { \u0026#34;Records\u0026#34;: [ { \u0026#34;eventVersion\u0026#34;: \u0026#34;2.1\u0026#34;, \u0026#34;eventSource\u0026#34;: \u0026#34;aws:s3\u0026#34;, \u0026#34;awsRegion\u0026#34;: \u0026#34;us-east-2\u0026#34;, \u0026#34;eventTime\u0026#34;: \u0026#34;2019-09-03T19:37:27.192Z\u0026#34;, \u0026#34;eventName\u0026#34;: \u0026#34;ObjectCreated:Put\u0026#34;, \u0026#34;userIdentity\u0026#34;: { \u0026#34;principalId\u0026#34;: \u0026#34;AWS:AIDAINPONIXQXHT3IKHL2\u0026#34; }, \u0026#34;requestParameters\u0026#34;: { \u0026#34;sourceIPAddress\u0026#34;: \u0026#34;205.255.255.255\u0026#34; }, \u0026#34;responseElements\u0026#34;: { \u0026#34;x-amz-request-id\u0026#34;: \u0026#34;D82B88E5F771F645\u0026#34;, \u0026#34;x-amz-id-2\u0026#34;: \u0026#34;vlR7PnpV2Ce81l0PRw6jlUpck7Jo5ZsQjryTjKlc5aLWGVHPZLj5NeC6qMa0emYBDXOo6QBU0Wo=\u0026#34; }, \u0026#34;s3\u0026#34;: { \u0026#34;s3SchemaVersion\u0026#34;: \u0026#34;1.0\u0026#34;, \u0026#34;configurationId\u0026#34;: \u0026#34;828aa6fc-f7b5-4305-8584-487c791949c1\u0026#34;, \u0026#34;bucket\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;lambda-artifacts-deafc19498e3f2df\u0026#34;, \u0026#34;ownerIdentity\u0026#34;: { \u0026#34;principalId\u0026#34;: \u0026#34;A3I5XTEXAMAI3E\u0026#34; }, \u0026#34;arn\u0026#34;: \u0026#34;arn:aws:s3:::lambda-artifacts-deafc19498e3f2df\u0026#34; }, \u0026#34;object\u0026#34;: { \u0026#34;key\u0026#34;: \u0026#34;b21b84d653bb07b05b1e6b33684dc11b\u0026#34;, \u0026#34;size\u0026#34;: 1305107, \u0026#34;eTag\u0026#34;: \u0026#34;b21b84d653bb07b05b1e6b33684dc11b\u0026#34;, \u0026#34;sequencer\u0026#34;: \u0026#34;0C0F6F405D6ED209E1\u0026#34; } } } ] } Now further you need to implement the lambda code to process your records.\n","date":"Jun 20","description":"It's all about triggers.","permalink":"https://blog.devutkarsh.com/using-aws-s3-and-lambda-to-process-file-chunks/","tags":["aws","microservice","file chunks"],"title":"Using AWS S3 and Lambda to process file chunks"},{"categories":["tech"],"contents":" Understanding the world of cloud computing and high-speed internet. Technology has moved to the cloud, it was just 11 years ago when I was puzzled by the word cloud computing. Luckily back then I had access to free internet and Google search engine to kill my curiosity.\nIt was when I was sitting copying all the pictures from the college fest to a pen drive so that we can share them with everyone else. The world has now changed to \u0026ldquo;I will share on Google photos!!\u0026rdquo; Well that is cloud storage for you. What\u0026rsquo;s next?\nCloud gives you the flexibility to store all your data backups on to a remote server far far away. We just need to trust enough that the cloud providers have a better Hard Drive that won\u0026rsquo;t crash ever. Haha. Obviously, we gotta pay for the access. And if you think it\u0026rsquo;s free, then it is only till we all get addicted, just like the internet and smartphones.\nThen comes cloud computing when you don\u0026rsquo;t need those graphics renderers and the crazy system requirements for your computer. All CPU, GPU that is required to run a heavy software or game is done on the cloud, all you need is a damn fast internet connection. It isn\u0026rsquo;t too far when XBOX and PS will be obsolete. Google Stadia is almost there to crash it all on gaming.\nWith cloud computing becoming the next big thing, we will only need an interactive screen, a browser, and a cloud provider. Oh, we already have Chrome and smartphones. Yeah, we just need to buy subscriptions. No cracks and activation cheats! There you go, Netflix and Chill!\nWhat do you think? What else will revolutionize technology in the future? Do share your thoughts in the comments below and spare my sarcasm. :p\n","date":"Feb 28","description":"Sometimes I shit simple things that we all know.","permalink":"https://blog.devutkarsh.com/how-high-is-technology-in-2021/","tags":["cloud"],"title":"How high is technology in 2021?"},{"categories":null,"contents":"","date":"Nov 26","description":"","permalink":"https://blog.devutkarsh.com/articles/","tags":null,"title":"Articles"},{"categories":["tech"],"contents":" How to write an api-service or edge-service or api-gateway? So we are here today to write a gateway microservice using Springboot framework, Netflix\u0026rsquo;s Zuul library, and our never-getting-old programming language Java. As a part of this development, we will be using Gradle to build this together and prepare the Docker image out of it.\nIf you are not sure yet, what this api-service is going to help you with, I recommend reading out What is api-microgateway?.\nFirst create a Gradle project in your favorite IDE. Update the build.gradle file with following settings - 1 2 3 4 5 6 7 8 9 10 plugins { id \u0026#39;org.springframework.boot\u0026#39; version \u0026#39;2.3.3.RELEASE\u0026#39; id \u0026#39;java\u0026#39; id \u0026#39;application\u0026#39; } apply plugin: \u0026#39;io.spring.dependency-management\u0026#39; dependencies { implementation \u0026#39;org.springframework.boot:spring-boot-starter-web\u0026#39; implementation \u0026#39;org.springframework.cloud:spring-cloud-starter-netflix-zuul\u0026#39; } Refresh your Gradle project to download the defined dependencies from their respective repository. Update your main class of the Java application with SpringBoot and Zuul Annotation as below - 1 2 3 4 5 6 7 @EnableZuulProxy @SpringBootApplication public class ApplicationEntryPoint { public static void main(String[] args) { SpringApplication.run(ApplicationEntryPoint.class, args); } } Now your basic api-gateway is ready to serve but needs to be configured with routing settings.\nEdge Service or Routing Endpoint To set up routes, we will modify the application.yaml file which is responsible for helping our spring boot application in reading the dynamic configs.\nUpdate settings in your application.properties or application.yaml as follows - 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 spring: application: name: api-service server: port: 8080 zuul: routes: example: url: https://example.com ribbon: eureka: enabled: false Here in the setting the child property under zuul.routes which is example is the URI path or say serviceId which is responsible for redirecting the request to the targeted endpoint that is mentioned as the value for url property.\nNow you can run your spring-boot application and hit the localhost:8080/example on the browser.\nSo any request that we make after running our application and hitting the endpoint http://localhost:8080/example/xyz will send all requests and headers to downstream service at http://example.com/xyz\nThe response from the downstream service is then sent back and our api-service which in turn sends the response to the requesting client which will be your browser.\nSecurity Filters or Request Filter This is an add-on to your routing service where you can write a filter that can modify your headers or check for Authorization. Basically, any sanitization that needs to be done on the request before sending it further downstream can be applied here.\nCreate a new class RequestFilter.java and extend the abstract class ZuulFilter. As a part of your inherited behavior of ZuulFilter you will then need to override the below mentioned 4 methods :\nshouldFilter() - responsible if you want to enable this filter or not.\nrun() - the logic on how what needs to be done with the request.\nfilterType() - evaluates when this filter need to be applied i.e. pre, post or route.\nfilterOrder() - if there are multiple filters operating, then on what order does it comes.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class RequestFilter extends ZuulFilter { @Override public boolean shouldFilter() { return true; } @Override public Object run() throws ZuulException { RequestContext ctx = RequestContext.getCurrentContext(); System.out.println(\u0026#34;Requested Endpoint : \u0026#34; + ctx.getRequest().getRequestURI()); // all the logic goes here for request manipulation return null; } @Override public String filterType() { return \u0026#34;pre\u0026#34;; } @Override public int filterOrder() { return 5; } } Your main application class needs to define the Bean for this request filter to help Zuul servlet chain the filter settings.\n1 2 3 4 5 6 7 8 9 10 @EnableZuulProxy @SpringBootApplication public class ApplicationEntryPoint { public static void main(String[] args) { SpringApplication.run(ApplicationEntryPoint.class, args); } @Bean RequestFilter getRequestFilterBean(){ return new RequestFilter(); } Similarly you can create a response filter with filterType as Post and that can be used to manipulate the response from your downstream service before sending it back to your browser client.\nA complete sample of this can be found on my git repository -\u0026gt; api-microgateway\n","date":"Jun 11","description":"How to write an api-service or edge-service or api-gateway?","permalink":"https://blog.devutkarsh.com/api-microgateway-service-using-netflix-zuul-on-java/","tags":["aws","microservice","java"],"title":"API-microgateway service using Netflix Zuul on Java"},{"categories":["travel"],"contents":" I HOLD THAT A STRONGLY MARKED PERSONALITY CAN INFLUENCE DESCENDANTS FOR GENERATIONS. ~ BEATRIX POTTER Hampi and the lost stories in the ruins. It is a beautifully broken Hindu kingdom along Tungabhadra river which is just 300km from Bangalore. So one weekend I planned to travel and went with my friends to reveal the history behind. We took a direct train from Yeshwantpur railway station on a Friday evening to Hosapete to cover the most of the journey and then took an auto rickshaw to travel the remaining 10km and arrived at Hampi on a warm Saturaday morning.\nIt was October 2018, so it had started to be a little cooler in the town with no mobile networks which gave us peace deep down into our soul. We stayed at the other side of the river because that\u0026rsquo;s where you get bike for rent and most of the ruins to see, instead of staying at the holy temple side. We crossed the river on foot as there was not much of the water flow and took a self driving moped after checking into one of the homestays.\nLandscape of Hampi from Monkey Temple\nAfter getting fresh and having brunch at Wispering Woods, we went for sighting and did local boating which was amazing experience. In the evening we gathered the energy and climbed the stairs to reach Monkey Temple for the breathtaking view and sunset. Also we saw amazing musician who called themselves Yatao were playing soothing Handpan instrument.¬†Along with humans, you will find a lot of monkeys roaming around looking for food. Beaware as they snatch food at times. So after watching the beautiful sunset we headed towards Evergreen Guest house and cafe. Spent rest of the evening there playing music instruments and singing with people from around the world, which was an amazing experience in itself.\nVirupaksha Temple\nThe next day was spent in local sight seeing. We went to Dam and Virupaksha Temple. Since it was a weekend trip, we left from the place in the evening after returning our bikes.¬†Got on the bus to Hosapete and then on the train to Bangalore.\n","date":"Jan 26","description":"Monkeys only.","permalink":"https://blog.devutkarsh.com/hampi-world-heritage-site/","tags":["karnataka","hampi","ancient","ruins"],"title":"Hampi - World Heritage Site"},{"categories":["travel"],"contents":" WELL, I KNOW NOW. I KNOW A LITTLE MORE HOW MUCH A SIMPLE THING LIKE A SNOWFALL CAN MEAN TO A PERSON. ~ SYLVIA PLATH Well, I started pretty early in the morning at 4am. I had not slept this night. This was a sudden plan and urge to visit Auli that I went to travel on. Rishikesh was already doing so good but I the wanderlust. It asked me to go more, see more, feel more and live a little more. So I boarded the government bus of Uttrakhand that passes from the Zostel.\nIt was December and all foggy, the roads unclear along with the ongoing construction work being done to make better roads to Joshimath.\nUnknown Place on the way to Joshimath\nIt took me 12 hours to reach Joshimath while still most of the time not sleeping because I didn\u0026rsquo;t wanted to miss the beautiful hills covered with snow. Kids walking to school and everything was just so nostalgic. My back was hurting but this was the only cheapest option to travel in budget I had. I reached Joshimath town surrounded by all the beautiful hills from all side. My original plan was to travel more from Joshimath to Raini village which was around 20 kms ahead to stay with my couchsurfing host Vivek Rana. It had snowed recently around the hills and so the villages and Joshimath town were facing electricity cut for a week now. I could not contact him and took a hotel with cheapest cost for 2 days. Today I needed rest and tomorrow I have to spent my day in Auli. Had dinner at a local shop and went to bed.\nBest Chicken at Dhaba opposite to Hotel Trishul, Joshimath\nNext day I went to get the ticket to Auli Ropeway. You would not get the ticket it one go if you have not prebooked. It\u0026rsquo;s not that easy. Its operated by government and now you can understand how it works. So after a lot of pleading to different officials I got a ticket. The ropeway journey made it more amazing. On reaching the top of Auli with all snow all around. I was trying to make balance on such tough landscape. I tried skiing for 3 hours. Gopi, my skiing guide became my friend, and told all the great stories. Fell down for around 20 times while skiing, he picked me up every time. Such great people. Also, the place had a beautiful view. It cleared out my head.\nView from Auli\nAfter having an amazing day, I went back to Joshimath. I realized later in the night how much body pain was there because of the thrilling day, but I smiled. I shivered while wearing my jacket and having the quilt on. It was -9 degree in Joshimath today. But I smiled. And you may ask why? I was thrilled. I was happy. I was on my own. I was my tour guide and I was my guardian. And obviously I was creating the beautiful memories I can later tell stories of, before I get too old. I was living.\nThe next morning again at 4am I took the bus and reached back to Rishikesh. Then next day to Bareilly and then to Lucknow, my hometown to see my parents.\n","date":"Dec 29","description":"I was freezing but was happy because I was living.","permalink":"https://blog.devutkarsh.com/auli-joshimath-snow-skii-india/","tags":["uttrakhand","solo travel","joshimath","auli"],"title":"Auli \u0026 Joshimath - Snow \u0026 Skii India"},{"categories":["travel"],"contents":" LIFE IS SOMETHING WE ALL ARE SCARED OF. I have been to Pondicherry twice. Once with my friend and band\u0026rsquo;s drummer, Ankit Godle and next time with my friends from Bangalore. Both time from I travelled from Bangalore, once by bus and next time taking a self-driving car.\nThe first time I visited was in 2016, when I visited Chennai to meet Ankit for a new song composition. On reaching Chennai we thought to visit Pondicherry and so made a spontaneous plan and took a bus to Pondicherry. We only had a day so we took a ferry to Paradise Island.\nFerry to Paradise Island Beach\nAfter spending some nice time we went to rock beach and then returned back to Chennai.\nWell this was how I visited it for the first time. The next trip happened was by self-driving. Which was amazing as we followed Google Maps which took us from a bad and longer route. But that\u0026rsquo;s what the amazing thing is, the adventures. We reached Pondicherry by afternoon as we started early and checked in to AirBnb. As we all were tired we spent some time on the beach and then done for the day.\nThe next day we chilled at few places, the amazing French colony and the rock beach front with so many people enjoying life with their loved ones. Though it was pretty exhausting day with traffic and traveling around the city.\nAlso, went to an amazing The Motorcycle Diaries cafe later in the evening and then left back for Bengaluru via Chennai. And it was one hell of a road trip.\n","date":"Dec 06","description":"Should we continue music or not?","permalink":"https://blog.devutkarsh.com/pondicherry-last-french-colony/","tags":["tamil nadu","beach"],"title":"Pondicherry - Last French Colony"},{"categories":["travel"],"contents":" A VILLAGE IS A HIVE OF GLASS, WHERE NOTHING UNOBSERVED CAN PASS. ~ CHARLES SPURGEON Just the end of 2014 after graduating from college, I started my first job in Mumbai. While I was just a learner of professionalism at workplace, I met many like minded acquaintances and became friends in no time. After all the amazing trainings were done, the 2 month program had also created amazing friendships. So with all these friends, we planned a day trip to Bhandardhara which was a village just 185km from Mumbai. There weren\u0026rsquo;t many reviews on the web then, so had to figure it ourselves.\nBoat ride to cross the lake to Ratanwadi\nAfter reaching Bhandardara, there we had to take a boat ride to cross the lake and visit the Ratanwadi village. As we reached Ratanwadi, we realised that it was a small place with a temple and very few houses. There was no restaurant and we all were hungry, when a villages agreed to prepare food for all 10 people. We had stunning food and wanted to trek to the Ratanwadi fort, but we were already running late and had least stamina to go for trek.\nAmriteshwar Temple, Ratanwadi village\nSince, we had booked a traveler bus and had to also head back, most of them backed out to go for a trek as it was getting late. So we missed the trek which was supposed to give us the breathtaking view of Mumbai city. But understanding the need of the friends, we skipped the trek and after enjoying the beautiful Ratanwadi village we left back for Mumbai. It was a great day and great village indeed.\n","date":"Dec 05","description":"Sailing under the night sky in Mumbai outskirts..","permalink":"https://blog.devutkarsh.com/bhandardara-mumbai-overview/","tags":["maharashtra","bhandardhara","arthur dam"],"title":"Bhandardara - Mumbai Overview"},{"categories":["travel"],"contents":" LIFE IS EITHER A DARING ADVENTURE OR NOTHING. There was a time when I wanted to escape office. It was a weekend of November 2015 and we had no plans. Recently one of my friends had shifted to Mysore for work. So I asked my flatmate \u0026amp; friend Aprit, if he is interested in visiting traveling to Mysore to meet our common friend Adarsh. We left at night and took an early morning train from Yeshwantpur Railway Station, Bangalore to Mysore. On reaching Mysore, more plans unravelled and we hired two scooty and then we all three left for Wayanad in Kerala.\nRental scooty at Wayanad\nIt was a tiring ride and driving through Bandipur Tiger Reserve kept us going out of fear. Though we made it to Wayanad by evening. After reaching we just slept and straighten our backs. The next day we planned to explore the beautiful coffee estates and also visited the Edakkal Caves. But we missed visiting Chembra peak because of time constraint. But we managed to enjoy to the fullest on our scooters.\nSome random Coffee estate\nWayanad is a beautifully preserved region of Western Ghats and have scenic beauty of green plants and amazing people. We tried banana dishes and pakori along with chutney. The language difference while billing was taken care by a 7 year old boy who translated the amount to be paid between his father and us. To which I feel good that kids are more smart then we think and nation is progressing, even maybe a little. The amazing local food of Kerala and the super loving people gave me the best memories of the down south.\n","date":"Dec 05","description":"I also saw a dead snake too.","permalink":"https://blog.devutkarsh.com/wayanad-kerala/","tags":["kerela","wayanad","biking","weekend travel"],"title":"Wayanad - Kerala"},{"categories":["travel"],"contents":" IT IS BETTER TO TRAVEL WELL THAN TO ARRIVE. ~ BUDDHA One fine weekend me and my friends from Bangalore planned to visit the famous Chikmagalur district. So I called them up on a Friday night and took a government bus on a Saturday morning. It was 4-5 hours journey from Bangalore. We all just had a bagpack with only clothes and essentials.\nWe took a lodge instead of getting into any fancy hotel. After keeping our bags we went to get a bike, which was arranged for us by my friend Arpit\u0026rsquo;s colleague at work.\nA cliff on the way to Mulyangiri\nSo we got just one bike and we were three people. Chikmangalur being a small town we planned to do tripling. After satisfying our tummies, we went for local sightseeing. Till now the trip was amazing seeing the beautiful villages around Karanataka, the weather was pleasant. We went to see a Dam and then lakes. The next day morning we had planned to visit the Mulyangiri trek. Since the region was under control of forest department, we were not able to get through bike so we parked our bike and trekked.\nView from Mulyangiri Trek\nThe trek was super amazing. Moving through the jungle and steep cliffs sometimes. It took us like less than 2 hours to reach the top and that was breathtaking. The cloud moving fast and low, flowing through us. At top there was temple so we visited there, took some rest and then started to descend back. Since we were on foot, we took lift by a lorry and came back to the town. After that the weekend was again over and we left for Bangalore yet again.\n","date":"Dec 03","description":"Bike and tripling. We all have done.","permalink":"https://blog.devutkarsh.com/chikmagalur-karnataka-the-mullayanagiri-trek/","tags":["karnataka","chikmagalur","mulyangiri"],"title":"Chikmagalur, Karnataka - The Mullayanagiri Trek"},{"categories":["travel"],"contents":" THERE‚ÄôS SOMETHING THAT HAPPENS TO YOU WHEN YOU COME BACK TO YOUR HOMETOWN. ~JOSEPH DOUGHERTY¬†Ah! Lucknow, the most amazing city of memories. Such a calm city with kids playing cricket at almost every corner. That\u0026rsquo;s how I grew up at least. It has changed with time too, but still holds such a beauty every time I visit.¬†The amazing Charbagh Railway Station to iconic Aminabad. With progressive Gomti Nagar to chilled Jankipuram and from Aashiyana to Bara Imambara. While the whole city growing around the glittering Hazratganj. This is how Lucknow has been.\nBada Imambara\nThe city is simple and serene with all people lost in happy moments of kindness and smiles. Where harmony has always prevailed because of the amazing people. I can\u0026rsquo;t even unclutter my mind with places I want to list down to visit when in Lucknow. It\u0026rsquo;s vibe is amazing when you visit the Bada Imambada and Residency. Also, when it comes to food and you are a non-vegetation you can\u0026rsquo;t skip and not be here.\n","date":"Dec 03","description":"Ghar. Jahan aa ke sab theek ho jata hai.","permalink":"https://blog.devutkarsh.com/lucknow-uttar-pradesh-city-of-nawabs/","tags":["uttar pradesh","hometown"],"title":"Lucknow, Uttar Pradesh - City of Nawabs"},{"categories":["travel"],"contents":" ADVENTURE IS WORTHWHILE. ~ ARISTOTLE It was just two days after my birthday. I was in Lucknow for Diwali and had booked a ticket via Varanasi to Bangalore to travel back after vacations. Well that was the plan, and my train was supposed to be in Varanasi 5 hours before my flight. And I must tell, you can never predict what\u0026rsquo;s gonna happen next.\nThe winters had already hit the North India and that means it will be sooner when the visibility gonna go down with dense fog. And that\u0026rsquo;s exactly what happened on 13th November 2018. My train got delayed by 4 hours and I have to miss the flight because I had missed the boarding and did not do a web check in either. So after struggle, I got a next day flight and had to stay in Varanasi. Today was another big festival which was Chhath Pooja and I experienced it in a magical way.\nView of Assi Ghat from Boats\nSo, I checked into a hotel and left to explore the amazing \u0026ldquo;Banaras ki galiyan\u0026rdquo;, i.e. streets of Varanasi. In the morning I went for Assi Ghat and saw Aftaab Shivdasni shooting for his next movie. Had some tasty Bhelpuri on the Ghats and wander around. By evening I saw the amazing Ganga River aarti. After it was time a lot of women gathered along with their families and kids to continue the Chhath Pooja Ceremony.\nChhath Pooja at Ghats of Varanasi\nI was filled with love, religion, I felt patriotic and so amazed to see the India that lives together and thrives together. I also went to few temples and experienced the magnificent structures around. With so many glittering Diyas and continuously ringing bells, it was an awestruck evening.\nAfter an amazing day in Varanasi, I had dinner and came back to my hotel room lost in the experience of life around. Next day I left back for Bangalore and told stories about my day in Banaras.\n","date":"Dec 03","description":"Jai Bholenath.","permalink":"https://blog.devutkarsh.com/varanasi-or-kashi-city-of-ghats/","tags":["uttar pradesh","banaras","festival","day travel"],"title":"Varanasi or Kashi - City of Ghats"},{"categories":["travel"],"contents":" NOT EVERY LAKE DREAMS TO BE AN OCEAN. BLESSED ARE THE ONES WHO ARE HAPPY WITH WHOM THEY ARE. ~ MEHMET MURAT ILDAN Nainital happened like an impromptu. I was in Delhi meeting few friends when the two of decided to visit Nainital the next day. Also, it was a weekend. We booked bus tickets and started next day in the evening around 9pm. We reached Kathgodam the next morning and from there we got on the shared taxis that run between Kathgodam and Nainital. It took us another hour but we were in Nainital by 8am. We had our hotel View Point Resort booked in Mallital. They arranged cabs for us to pick up from the bus stand as well, which was a good experience.\nNainital Lake\nThen we checked in and took some rest. Had tasty aloo paratha and then left for sight-seeing post lunch. We had an amazing view of Himalayas from snow view point and then took the ropeway to descend to the mall road which is a famous shopping and hanging spot for all tourists. Walked a little and explored the famous market and amazing momos. The lake was amazing so we did boating and also visited the Nanda Devi temple. The day one was pretty exhausting and spent well.\nThe next day we decided to book a cab and see the places that were a little far like Caves, Tallital and suicide point etc.\nView from Sariyatal\nIt was so amazing to see villages spread out around different lakes making the landscape more beautiful. After a long hour sight seeing I went for lunch and had Dosa near one of the waterfalls.\nWith the afternoon, I had planned to check out with luggage and then head back to Delhi. This was really a weekend spent well in the cozy lapse of mountains and lakes.\n","date":"Jan 25","description":"I have Never seen so many lakes before.","permalink":"https://blog.devutkarsh.com/nainital-city-of-lakes/","tags":["uttrakhand","lakes","weekend trip"],"title":"Nainital - City of Lakes"},{"categories":["travel"],"contents":" ALWAYS DO WHAT YOU ARE AFRAID TO DO. ~ RALPH WALDO EMERSON Boat Ride in Dawki River\nIt was 11th of October 2017, I had already been tired with solo journey and exhausting treks of Cherrapunji. I had planned to travel to Dawki today. It was hardly 90Kms from here and Google Maps kept me informed that it won\u0026rsquo;t take you more than 3 hours to reach the spot. I had planned to stay at a camp in Dawki and had already called Pyndap, who was going to help me with my stay in Shnongpdeng which was the major camping coast point along Dawki river.\nSo before starting for Dawki, I gave good rest to my body and checked out at standard time. Had brunch on the way and left for Dawki to experience the point where Indian borders handovers the river to Bangladesh. It was already 3pm when I reached Mawmyrsiang and got confused which route to follow. When coming from Cherrapunji, there is a bypass via Nonglim which cuts down the travel time and distance to Dawki while the outer highway route was Umtyngar. In 2017, the bypass had started to build with no road and no vehicles passing by though that lush green villages.\nI thought to take a chance and started moving, on seeing the dark jungle before dawn, I got scared and thought to take the main road instead. So I took a U-turn after travelling like 3 km on the bypass. Sometimes in life when you are alone, you have to take a longer route cause adventure and safety should go hand in hand. But when I returned back to the main road I saw few Taxi\u0026rsquo;s carrying tourist taking the bypass, so I again took a U-turn and followed the Taxis instead of being alone on the bypass. It was scary and thrilling at the same time.\nBy 4.30pm, I was in Dawki. Yeah, I got late cause I was strangled in thoughts for choosing the right and safe journey. Also, when traveling to Dawki there were times with plain old farms and no humans around. No vehicle, no animals and not even internet for streches like 10kms. On seeing the Indian Military, I felt relieved.\nSince, I didn\u0026rsquo;t have much planned I did boating in the cleanest river and enjoyed the sunset. Also, there is a market for exchange between India and Bangladesh border running on boats. I enjoyed the evening and went to my camp later.\nCamping along Dawki River in Shnongpdeng\nAfter an exciting day, I met Pyndap and his friends, Lur Talang and others. We shared some drinks and enjoyed great non-vegetarian food along the Dawki river with conversations around great music that Meghalaya has seen.\nThe next day was so warm and good, I planned to return to Shillong and prepare for my journey back to Lucknow.\nAlso, here is a link to a song which that helped me writing this post.\nCrosstown Traffic by Jimi Hendrix\n","date":"Oct 11","description":"Maybe I am not in India. What if I crossed the border?","permalink":"https://blog.devutkarsh.com/dawki-and-the-bangladesh-border/","tags":["meghalaya","dawki","bangladesh border","camping"],"title":"Dawki - And the Bangladesh Border"},{"categories":["travel"],"contents":" THE WAY I SEE IT, IF YOU WANT THE RAINBOW, YOU GOTTA PUT UP WITH THE RAIN. ~ DOLLY PARTON Laitlum Grand Canyon View from Shillong - Cherrapunji Highway\nOnce I started for Cherrapunji, it was cold morning already with no sun and the sky covered with blanket of cloud. The sky was white and I knew that it is going to rain today. Also, the Geography books that I read since my childhood told me, Cherrapunji receives the highest rainfall every year. So it was sure that was going to rain today.¬†I started in bright sun at around 10AM in the morning but while I reach the Latilum, the sun was no more following. From highway to Cherrapunji, it was an amazing view of Latilum Grand Canyon. The green lush hills, all standing together like a band and the winds playing the beautiful music in synchronicity. I took a break and enjoyed the view before continuing.\nBy around 5PM, I reached the calm and serene Sohra, where I checked into my hotel and took some rest from long driving day. Late in the evening, I explored the surroundings. There were no big restaurants or shops. Local people running canteens and selling daily goods across corners. The most amazing thing I noticed all the way in Meghalaya that everywhere I went, it was pretty neat and clean. I had my dinner and came back to room. Also it started drizzling.\nNext day was warm. I woke up early in the morning at 5AM and started for the Double Decker Root Bridge because I wanted to see this natural bridge formed by locked roots of Banyan tree. It was not easy to reach there. After 12km of bike ride into the valley, I reached a stop from where I had to trek for about 6KM. I was alone, tired and scared of the jungle at 6.30AM in the morning. I didn\u0026rsquo;t knew what\u0026rsquo;s ahead. So I took a local guide with me. His name was Kevin. I had a bluetooth speaker in which I was playing few songs so Kevin asked me to play few of his favorites. I explored great 90\u0026rsquo;s music with him and one of my favorite is Country Roads take me home by John Denver.\nWe trekked to Living root bridge and it was magnificent.\nDouble Decker Living Root Bridge - Tyrna Village, Cherrapunji\nI was all exhausted with the 6km already and I had to trek back so to keep up my energy, I had maggi and tea at Wahlang Tea Stall. After an hour break I started to trek back and it was not easy. With energy going down and stairs going up, this was the toughest afternoon ever. This 12km of round trip had got me cramps in my legs so I went back and took rest for the day.\nThe next day I went for the great view of Seven Sister Waterfalls, Eco Park and Mawsmai Caves which were equally beautiful places. Did some shopping, enjoyed the drizzles in the evening and took rest to start the journey next day to Dawki.\n","date":"Oct 10","description":"And it Rained!","permalink":"https://blog.devutkarsh.com/cherrapunji-or-sohra-october-drizzles/","tags":["meghalaya","solo travel","cherrapunji","sohra"],"title":"Cherrapunji or Sohra - October Drizzles"},{"categories":["travel"],"contents":" I THINK THAT‚ÄôS WHAT IT IS WITH ROCK MUSIC. IT HELPS YOU HANG TOUGH, I GUESS. ~ ANGUS YOUNG Malki Grounds, Shillong\nWhat a beautiful drive to Shillong from Guwahati, it took around 3 hours to cover the 100 km stretch. It was drizzling when I started, got a little drenched as well. While I reached the city, I saw an amazing evening with an ongoing football match at Malki Grounds, meanwhile the sun was setting down. Then I went to my stay and met some amazing Graphic Designers from Shillong, and had a good time in rock city.\nNext day I went to explore some of Shillong and visited one of the beautiful Shillong peak and Elephant falls. Shillong peak is a small hill that gives you all the overview of the city.\nAlso, Elephant falls were wide and massive though it depends at what time of season you visit the falls.\nOn my way back I visited Police Bazaar to explore local cuisines and shops. There I found a shop serving tasty and hot Momos with Chicken soup. This was the first time I learned that Momos are meant to be served with Soup. That\u0026rsquo;s how they do it in North-East India.\nMy original plan was to visit the NH7 weekender in Shillong too, but unfortunately the events date got shifted and I was here is Shillong thinking where to go next. See, that is the beauty of traveling, the unplanned events will happen, no matter what or how efficiently you plan it. Some plans will not fall in place and will come out as an adventure for you.\nAfter spending almost one and half amazing days in Shillong, I started for Cherrapunji. Please visit the links to read further about my experiences from Cherrapunji or Sohra. The famous town for all the year rains.\nAlso, here is a link to a song which that helped me writing this post.\nGlycerine by Bush.\n","date":"Oct 09","description":"When I could not attend the Nh7 Weekender.","permalink":"https://blog.devutkarsh.com/shillong-rock-capital-of-india/","tags":["meghalaya","solo trip","rock capital"],"title":"Shillong - Rock Capital of India"},{"categories":["travel"],"contents":" GREAT THINGS NEVER CAME FROM COMFORT ZONES. There was a time I loved computers and Internet. Well a pretty neat invention of all time, getting us all done with a click. From having a virtual social life to setting up business, from making travels plan easier to flying to Moon \u0026amp; back.¬†Yes! We can have it all. But what we have? A machine holding us from all the beautiful adventures out there and making us¬†well assured that this life is easy and amazing at the same time.\nI had a pretty great time in 11 years span from school to college and then at work, all made easy with technology.¬†Until I started to realise, that work places are totally life changing, which plugs out the real country boy from you and turn you into a professional with jitters.\nI\u0026rsquo;ve been traveling for 2-3 years now, always taking small trips with friends \u0026amp; sometimes colleagues to nearby beaches and mountains. That was the time when people wanted to travel North-East India and explore the unknown 7 states of the country. With multiple failed plans in group, I decided not to waste time anymore and take a solo trip, and that was it.\nPunjabi Dhaba at NH27. Enroute to Shillong from Guwahati.\nSo, I read a lot of blogs, planned 2 weeks off from office and booked a one way air ticket to Guwahati, Assam. I planned 9 days to explore Meghalaya and then travel to my home town in Lucknow, Uttar Pradesh via train -¬†Guwahati New Delhi Special.\nAs I started my journey on Saturday morning from Bangalore. Travelling all the way to the airport, such a long ride, I started at 6 in the morning with a flight to depart at 9:20am. I was in Guwahati by 12 noon. Outside the airport was a freedom with warmth of Assam. I took a taxi to Himalayan Phoenix¬†Bike Rental from where I had pre-enquired for booking a Royal Enfield.\nAfter a little lunch, I went for Shillong, Meghalaya by 3pm on a long highway of National Highway 27.\nBy 7pm in the evening I was in Shillong, figuring out how to reach my Airbnb host, Ritchin who is a graphic designer \u0026amp; an amazing sketch artist.\nHad a great time in Shillong and then in Cherrapunji and Dawki. Please visit individual links to read further about my experiences from each town of Meghalaya.¬†While returning I stayed a day in Shillong. After riding to Guwahati all day long next day, I grabbed a beer at Underdogs and hopped on the train to Lucknow.\nWhile I was writing all this, I am also planning a trip to Auli, Uttrakhand.\nYou too can be a part of great memories, it\u0026rsquo;s just you have to plan it out and do it, anyways.¬†Money is all papers. Have a good day.\nAlso, here is a link to a song which that helped me writing this post.\nAll I wanted was a car by Brad Paisley\n","date":"Oct 08","description":"First Solo Trip of My Life.","permalink":"https://blog.devutkarsh.com/meghalaya-my-first-solo-trip/","tags":["meghalaya","solo trip","biking"],"title":"Meghalaya - My first solo trip"},{"categories":["tech"],"contents":" Where is this blog coming from? The biggest driving force will always be curiosity, and if you have it, your focus will lead you where you want to be!\nI have always been curios to explore, the wild in nature, the depth in music and everything else. Always trying to learn more and grasp knowledge while grow spritually. But that becomes problematic if you try to hop on multiple boats because time is quantifiable.\nHave a plan on how you spend your time, than how you spend your money.\nOver the years of hopping multiple passions I finally realized that what I love most is around three things mostly.\nTechnology - Starting from burning CD\u0026rsquo;s to downloading Cracks. Reverse engineering to hacking and then finally settling as a Software Engineer. This road I am always traveling. Travel - You learn from experiences of others. And I met beautiful people while I traveled India and heard all their crazy stories. It made me humble and wise over the years. Exploring nature, feeding these animals, laying down under trees, and this just calms me down. Music -Always loaded with ideas and thinking what little difference I can have to make this world a better place. So from writing blogs to writing poetry. From poetry to writing songs, music has helped me a lot. Can\u0026rsquo;t give up on this meditation strategy. The tech behind the blog! The tech is fairly simple, and is hosted for free on Github. The only thing involved as a cost is the domain name.\nIt is a static website and all the webpages are static as well. It uses Hugo template to generate HTML webpages for blog posts out of a Readme file written using markdown. Have added some custom JS and CSS for styling stuff. For any new post, I just write a readme.md and check-in it to the master branch.\nI utilize github actions as my Continous Integration and Continous Deployment. On check-in to master branch a pipeline action is triggered and generated static webpages are committed/pushed into another branch named gh-pages. This branch is my static hosting from Github Pages to which the nameservers are pointed via GoDaddy.\nAll this you can checkout on my github repo here.\nIf you want to say hello or hangout over a cup of coffee, I am all over the social media. üëã\n","date":"Nov 15","description":"Just another mandatory SYSOUT to see if everything works fine.","permalink":"https://blog.devutkarsh.com/hello-world/","tags":["blogging","hosting","dns"],"title":"Hello World!"}]